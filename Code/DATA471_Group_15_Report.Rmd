---
title: "DATA471 Group Report"
author: "Group 15: Izzy Bremnar, Tram Chau, Kim Downing and Amish Verma"
date: "`r Sys.Date()`"
output: html_document
---

# Title

• Project title, names and IDs of students in your project group, date of submission

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data

```{r}
covdf <- read.csv('../Data/covid_19_data_portal.csv')

anzdf <- read.csv('../Data/new-zealand.anz-activity-outlook.csv', 
                  sep='\t')

pmidf <- readxl::read_excel(path = '../Data/PMI-Time-Series-Data.xls', 
                            skip=1)
names(pmidf)[1] <- 'DATE'

jobdf <- readxl::read_excel(path = '../Data/Seek_NZ_data_01-07-2023.xlsx', 
                            sheet = 'SEEK Job Ad Index')

appdf <- readxl::read_excel(path = '../Data/Seek_NZ_data_01-07-2023.xlsx', 
                            sheet = 'SEEK Applications per Ad Index')
```




# Background and Data [1-3 pages]

• State which dataset(s) your group worked on, and their source

• Explain briefly why the dataset is of interest, or what questions it could be used to answer; assume that the reader has never heard of your dataset

• State the types of data in the dataset(s) and the structure of the dataset(s). Are the data numerical, categorical, or both? Time series? Coordinates? Diagnostic categories? This does NOT need to be an exhaustive list of every variable, just a few comments on the overall types.

• State how complete the dataset(s) are (i.e. how many missing, any structure to the missing data, whether there are errors in the data)

• If you used more than one dataset, state what steps you had to take to integrate the datasets




# Ethics, Privacy and Security [1-2 pages]
• Brief discussion of any ethical considerations that apply to your project

• Brief discussion of any privacy concerns that might arise connected to your project

• Brief discussion of what steps you could take to keep your project data and results secure (you do NOT need to carry this out, you just need to talk about it in the report)

### Ethics

The dataset is produced by the Treasury and is made available under the [Crown Copyright, Attribution 4.0 International (CC BY 4.0)](https://www.treasury.govt.nz/publications/nzac/nzac-qa-note) license which allows free use, adaptation and distribution of the data as long as the source (the Treasury) is attributed, and a link to the license is provided (see earlier in the sentence).

This dataset is derived from constituent datasets that are also publicly available as either full datasets, or as data products. As far as we can tell, none of these datasets have licensing at all - although we believe it is reasonable to expect that the Reserve Bank has permission to utilise these datasets and publicly release their derivative product under their own license, which we will respect in using this data.

We also believe that this data was collected with informed consent (as it was mostly either measured values, or through a survey response) and we *assume* that this usage of the data falls within the original bounds of the consent. Here we need to trust that the Reserve Bank has ensured this fact.

The primary dataset has clear ownership, licensing/terms of use, and transparency of where the data came from. As long as we adhere to the terms of the license, it seems difficult to identify any ethical issues in the use of this dataset.

[[ ensure that we attribute the constituents here if they aren't linked in the prior section ]] 

### Privacy

This dataset is a series of monthly values which was modeled using multiple datasets. We note that some of the constituent datasets are derived from surveys which may have individual-level, identifying data (although we have not seen these datasets publicly available - these are more likely to be seen as data products). As the final, available data is tightly aggregated, we do not see any potential for de-anonymisation or risk of identifying data being released.

Based on the above, we do not believe there to be any obvious privacy issues with these datasets.

### Security

In uploading/updating the dataset on the appropriate website, they need to ensure that only the necessary people have the ability to access and modify these files. This is an access control mechanism to limit exposure as to who could potentially upload something malicious, or perhaps more likely, reuse a password and let in a blackhat who may choose to do the same.

We also need to be mindful here that the file itself is the correct one, and not some secret or embargoed data, and that it does not accidentally leak metadata (such as who worked on it, commentary from reviewers, exif data in case of images etc).

When the file has been uploaded, the database or server needs to be well defended to deter opportunistic (or targeted) attacks which may aim to change the file (malware, viruses etc - an integrity issue) or deny access to the file (DDOS - an availability issue). For this, we need a properly configured host, which can be a challenge for some (although hopefully not for either the Reserve Bank or Stats New Zealand).

When a user attempts to access/download the file, we must also ensure the integrity of the data from host to client. There are a few ways of doing this, but the most common would be by employing HTTPS in an attempt to thwart man-in-the-middle attacks. Additionally we might provide encryption, or a verification hash. A user might also elect to use a VPN or TOR-like browser, and a firewall and/or anti-virus. 

In the specific case of this dataset, StatsNZ offers HTTPS by default, although no verification hash we are aware of. It is difficult to know the specifics of their defenses (which is a good thing). The data is provided in a .csv file, which is a fairly safe filetype given it is pure text data (instead of something like a .pdf or office documents which can utilise macros).

We do not observe any particular security issues related to this dataset.

For our project, the main source of security issues would be in the communication and sharing of files between group members. We have set up a Github repo in order to do this sharing. The repo mitigates many of these potential issues that we might otherwise have in sharing files by email or discord. The repo also features strict access controls in the form of a white-list, and Github itself requires authentication to access (usually in the form of a ssh key or personal access token) which disallows contributions from bad actors (excluding anyone working a Github/Microsoft that is). Although, if one was conniving enough, the information contained in the Github repo may allow someone to do some social engineering, although the attacker would likely have to put in a lot of effort into a (very) low value target.

We do not have any specific counter-measures related to our project outside of good internet hygiene (don't go visiting dodgy sites, or clicking on emails from Nigerian Princes), use a firewall and/or anti-virus, knowing who your group members are, and limiting physical access to your devices.


# Exploratory Data Analysis [3-6 pages]

For this section, do NOT try to summarize everything you can find in the dataset(s). Select a subset, highlighting features that you thought were interesting in the data. The plots do not have to be complicated; simple bar charts and scatter plots are fine.

• Several summary tables and/or plots, each describing one, two or three variables in the data that you thought were interesting

• Explain the definitions of the variables in each table/plot

• Comment on the main features of each plot

• Include suitable labels and keys for each plot

• Make sure all plots would be readable if printed in black & white, and adjust the point sizes and/or line thicknesses to improve readability

• Lay out all tables so that they are clearly readable and clearly labelled, and do not use excessive significant figures

• All figures and tables should be numbered and should have captions

## Preprocessing data

• Select relevant columns for the indicators

• Convert date column to date data type

• All the time series data are monthly frequency, with different start and end month.

• Date value as the start of the month: covdf, pmidf, jobdf, and appdf

• Date value as the end of the month: anzdf

Thus, the date column of anzdf will be processed to the first date of the corresponding month.

Duration of each time series:

• convdf:10/2003 - 06/2023

• anzdf: 04/2008 - 07/2023

• pmi:   08/2002 - 06/2023

• jobdf: 01/2002 - 06/2023

• appdf: 02/2008 - 06/2023

```{r preprocess}
# Convert to date
covdf <- covdf[covdf$series_name == 'New Zealand Activity Index (NZAC)', c("parameter", "value")]
colnames(covdf) <- c("DATE", "NZAC")
covdf$DATE <- as.Date(covdf$DATE, "%Y-%m-%d")

anzdf <- anzdf[,c("Date", "ActualValue")]
colnames(anzdf) <- c("DATE", "ACT_OUTLOOK")
anzdf$DATE <- paste0(substr(anzdf$DATE, 1, 8), '01')
anzdf$DATE <- as.Date(anzdf$DATE, "%Y.%m.%d")

colnames(pmidf) <- gsub(' ', '_', colnames(pmidf))
pmidf$DATE <- as.Date(pmidf$DATE)

jobdf$DATE <- as.Date(jobdf$DATE)
jobdf <- jobdf[jobdf$STATE == "Total", c(1, 4)]


appdf$DATE <- as.Date(appdf$DATE)
appdf <- appdf[appdf$STATE == "Total", c(1, 4)]

alldf <- merge(covdf, anzdf, by="DATE", all = T)
alldf <- merge(alldf, pmidf, by="DATE", all = T)
alldf <- merge(alldf, jobdf, by="DATE", all = T)
alldf <- merge(alldf, appdf, by="DATE", all = T)
```

## Statistical summary of time series data

After the data is processed and merged into a single dataset, we look at the summary statistic of all the indexes. As the available data of indexes are different in start and end period, the dataset includes missing data points for certain indexes.

```{r statsum}

summary(alldf)

```

## Time series Visualization 

The plots below are showing the indexes over the period. They are grouped to show in the same plot for the relating meaning and scaling. Thus, there are 3 groups including 

• activity indexes (NZAC index and activity outlook index)

• production indexes (PMI, PRODUCTION, EMPLOYMENT, NEW ORDERS, FINISHED STOCKS, AND DELIVERIES)

• SEEK jobs indexes (Job Ads volumes index and Job application per ads volume index)

As per out project question regarding the possibility of NZAC index prediction. Thus NZAC index is base line for analysis. And we try to figure out  the other correlation between other indicators and NZAC index.

There are many missing data points for Activity outlook index over the period. The pattern was fluctuating significantly.

In the production group, all the indexes provide the similar pattern over the period. Thus, we can keep one index from this group for further analyzing on how this group index correlated to the NZAC index.

In the job group, job applications per ads volumes index is derived from the other index (ads volumes index). This explains the contrast patterns between them. During recession 2008 and pandemic 2020, the ads volumes index decreased dramatically, where as the job applications per ads volumes index increased accordingly. Likewise, post-pandemic period recorded the opposite trend of these two indexes the other way arround.

```{r viz, message=FALSE}
library(dplyr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(forecast)
```
```{r, message=FALSE}

ggplot(data = alldf, aes(DATE)) +
  geom_line(aes(y=NZAC, colour='NZAC')) +
  geom_line(aes(y=ACT_OUTLOOK, colour='ACT_OUTLOOK')) +
  ylab('Index (%)') + 
  theme_classic()


ggplot(data = alldf, aes(DATE)) +
  geom_line(aes(y=PMI, colour='PMI')) +
  geom_line(aes(y=PRODUCTION, colour='PRODUCTION')) +
  geom_line(aes(y=EMPLOYMENT, colour='EMPLOYMENT')) +
  geom_line(aes(y=NEW_ORDERS, colour='NEW ORDERS')) +
  geom_line(aes(y=FINISHED_STOCKS, colour='FINISHED STOCKS')) +
  geom_line(aes(y=DELIVERIES, colour='DELIVERIES')) +
  ylab('Index (%)') + 
  theme_classic()

ggplot(data = alldf, aes(DATE)) +
  geom_line(aes(y=ADS_SA_INDEX, colour='Job Ads volumes index')) +
  geom_line(aes(y=CA_SA_INDEX, colour='Job Applications per ads volumes index')) +
  ylab('Index (%)') + 
  theme_classic()

```

### Correlation plotting
```{r correlation}
alldf <- merge(covdf, anzdf, by="DATE", all.x = T)
alldf <- merge(alldf, pmidf, by="DATE", all.x = T)
alldf <- merge(alldf, jobdf, by="DATE", all.x = T)
alldf <- merge(alldf, appdf, by="DATE", all.x = T)
library(ggcorrplot)
corrmatrix <- alldf %>% select(NZAC, ACT_OUTLOOK, PMI, PRODUCTION,
                               EMPLOYMENT, NEW_ORDERS, FINISHED_STOCKS,
                               DELIVERIES, ADS_SA_INDEX, CA_SA_INDEX) %>% cor()
corrmatrix

corrmatrix_2 <- alldf %>% select(NZAC, PMI, PRODUCTION,
                               EMPLOYMENT, NEW_ORDERS, FINISHED_STOCKS,
                               DELIVERIES, ADS_SA_INDEX) %>% cor()
corrmatrix_2

ggcorrplot(corrmatrix_2,
           hc.order = TRUE,
           type = "lower",
           lab = FALSE)
```

### Decomposition Visualization

Following plots are showing the time series decomposition for each index. 

NZAC index pattern shows the impact of 3 main events during the period. Those were economic recession in 2008, the pandemic starting at the end of 2020 and the recovery after the pandemic since 2022 until now. Both 2008 recession and 2020 pandemic events caused a plunge in the NZAC index, but their patterns were different. The data shows that the NZAC index gradually decreased during 2008 bottomed at around -3%, while pointly drop to -10%. Post-pandemic recovers significantly in 2021 which peaked at over 30% (as it compares with last year drop -10%). 

The seasonal patterns shows two hikes every year.

```{r}
minP <- min(covdf$DATE)
covts <- covdf %>% arrange(DATE) %>% dplyr::select(NZAC) %>% ts(frequency = 12, start = c(year(minP),month(minP)))

(covts[,1] %>% decompose(type="multiplicative") %>%
    autoplot() + xlab('Time') %>% 
    ggtitle("NZAC Index: Multiplicative decomposition")) %>%
    print()

(ggseasonplot(covts[,1]) +
    ggtitle("Seasonal plot: NZAC Index") +
    xlab('Time')) %>% print()

covts_pre <- covdf %>% filter(year(DATE) < 2020) %>% arrange(DATE) %>% dplyr::select(NZAC) %>% ts(frequency = 12, start = c(year(minP),month(minP)))

(ggseasonplot(covts_pre[,1]) +
    ggtitle("Pre-pandemic - Seasonal plot: NZAC Index") +
    xlab('Time')) %>% print()
```

The PMI index trend is similar to NZAC index through out the period. Although the data is less smooth than the NZAC, this causes a recognizable more noise through out the entire period. 

The seasonal patterns shows two hikes every year, with one dip in the middle of the year.


Post pandemic, NZAC currently is flatten at around 0, while the PML is downward.

```{r}
minP <- min(pmidf$DATE)
pmits <- pmidf %>% arrange(DATE) %>% dplyr::select(PMI) %>% ts(frequency = 12, start = c(year(minP),month(minP)))

(pmits[,1] %>% decompose(type="multiplicative") %>%
    autoplot() + xlab('Time') %>% 
    ggtitle("PMI Index: Multiplicative decomposition")) %>%
    print()


(ggseasonplot(pmits[,1]) +
    ggtitle("Seasonal plot: PMI Index") +
    xlab('Time')) %>% print()
```

Jobs ads volumes index shows a clear upward trend in the period. Likewise, there are two pattern due to the two mentioned big events, recording the short-time downward before continuing climb up later on.

There is also clear seasonal patterns. There were big noise (remainder) during pandemic.

Seasonal pattern is different from the other two indexes. It rises at the beginning of each year, then plummet to a dip before rising a gain to the end of the year.

```{r}
minP <- min(jobdf$DATE)
jobts <- jobdf %>% arrange(DATE) %>% dplyr::select(ADS_SA_INDEX) %>% ts(frequency = 12, start = c(year(minP),month(minP)))

(jobts[,1] %>% decompose(type="multiplicative") %>%
    autoplot() + xlab('Time') %>% 
    ggtitle("Job ads volumes Index: Multiplicative decomposition")) %>%
    print()

(ggseasonplot(jobts[,1]) +
    ggtitle("Seasonal plot: Job Ads Volumes Index") +
    xlab('Time')) %>% print()
```


# Individual Contributions [1 page]

• State what contribution each member of the group made to the data preparation, the analysis
and the report




# Overall Report

These marks will be awarded for overall presentation, clarity and quality of the report.
In particular, marks will be awarded for

• A clear logical layout

• Keeping to the page limits for each section, and using sensible font size

• Key facts being easily located

• Readability of tables and plots

• Clarity of expression [Note: for non-native speakers of English: your English does not need to be perfect, it is the logic and correctness of your presentation that is most important. Nevertheless you are advised to get someone to proof-read your proposal.]

• Clear explanation of how your choice of exploratory plots and tables is relevant to your project, and how the ethical considerations apply to your project (i.e. not just a set of generalities)

• Make sure each time you use/refer to someone else’s work you cite the source in the text, and include the reference in the list at the end. It does not need to be a long list; you may only need one or two references.

• Referencing should be correctly done: a complete list of references must be included. You can use any referencing style you wish; APA is fine if that’s what you like.

The report should be written in a formal style. It should not be an aspirational document about what you would like to do in the next phase; rather, it should state what steps you carried out in the project up to this point, although you may include a few comments at the end about what your next steps might be.



